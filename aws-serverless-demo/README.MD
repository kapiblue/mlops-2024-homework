# Homework 1 - Serverless deployment of a model

### Introduction
The goal of this assignment is to deploy a model using serverless architecture. You are free to choose any cloud provider, though guidance will focus on AWS due to its extensive serverless ecosystem and its position as the leading cloud provider by market share.

### Exact requirements

The Lambda function should be triggered when an image is uploaded to an S3 bucket. The event generated by this upload will provide the Lambda function with the necessary information, including the URL of the file uploaded to said S3 bucket, that can be used to download the image (this can be achieved using the boto3 library). Ensure that the Lambda function has an appropriate IAM role with the necessary permissions (has assigned necessary policies) to access, download and save files on S3. After downloading the image, the Lambda function should perform inference (using any model, I recommend Hugging Face ones) and then save the results back to the S3 bucket. The model weights should be saved in the Docker image, such that they wonâ€™t be downloaded each time we invoke the lambda. As mentioned above, you are free to replicate this on Azure using Azure Functions and Azure Blob Storage. 

### Basic steps you may follow.
1. Install [AWS CLI](https://aws.amazon.com/cli/)
2. Create AWS account.
3. Go to AWS IAM  and create a new user in user section. Assign Admin Policy to him.
4. Generate an Access key for that user.
5. Configure access for CLI to your AWS account (CLI will authorize boto3 package / or Python AWS CDK)
```bash
aws configure
```
6. Write the Lambda handler, where the inference will be performed. 
The function should: Download an image from S3, perform inference, save the result back to S3.
Remember that the function name should follow specific convention, unless you change entrypoint (CMD) in the Dockerfile
7. Create a Dockerfile that will be used to containerize your code. In that Dockerfile you should pre-download the model weights in a separate python script / or just copy the wieghts.
Useful [Link](https://aws.amazon.com/blogs/compute/deploying-machine-learning-models-with-serverless-templates/)
8. Build your docker
9. Test your docker image
```bash
docker run -p 9000:8080 <repository_name>:<tag>
curl -XPOST "http://localhost:9000/2015-03-31/functions/function/invocations" -d '{}'
```
10. Authorize the docker for access to AWS ECR 1
11. Push the image to AWS ECR
12. Create the AWS Lambda with an appropriate IAM role (with appropriate policies assigned to said role.)
13. Create the S3 on-upload trigger.
In the AWS Console you can search for all said resources typing ECR for instance in the search bar.

### Useful links
- [AWS Lambda Trigger with S3](https://docs.aws.amazon.com/lambda/latest/dg/with-s3-example.html)
- [AWS CDK Examples](https://github.com/aws-samples/aws-cdk-examples/tree/main/python/lambda-s3-trigger)
- [ChatGPT](https://chatgpt.com)
- [Claude AI](https://claude.ai)


### Organizational Information.
1. Deadline: 30.10.2024
2. Don't prepare presentation. You will be asked to just share the screen and share your code, show that it works, and share with the rest of the class:
What caused problems? What took you the most time? General experience & any useful tricks used. 
3. I would suggest doing the project in pairs, but triples are also allowed. 
4. Two points will be assigned to those who will use AWS CDK or Azure CDK (Infrastructure as a code)



